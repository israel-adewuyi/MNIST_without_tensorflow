{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\"\"\"\n",
    "    The two lines up above are to suppress warnings. They should not affect the \n",
    "    code though.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models, layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Convert data to numpy array and shuffle\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Separate into training and testing sets\n",
    "test_data = data[0:8400].T\n",
    "test_label_data = to_categorical(test_data[0], num_classes=10)  \n",
    "test_pixel_data = test_data[1:]\n",
    "test_pixel_data = test_pixel_data.astype(float) / 255.0\n",
    "test_pixel_data = test_pixel_data.T\n",
    "\n",
    "train_data = data[8400:].T\n",
    "train_label_data = to_categorical(train_data[0], num_classes=10) \n",
    "train_pixel_data = train_data[1:]\n",
    "train_pixel_data = train_pixel_data.astype(float) / 255.0\n",
    "train_pixel_data = train_pixel_data.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(train_pixel_data.shape)\n",
    "print(np.min(test_pixel_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "525/525 [==============================] - 3s 2ms/step - loss: 0.7221 - accuracy: 0.7893\n",
      "Epoch 2/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.2869 - accuracy: 0.9182\n",
      "Epoch 3/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.2376 - accuracy: 0.9314\n",
      "Epoch 4/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9397\n",
      "Epoch 5/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1956 - accuracy: 0.9431\n",
      "Epoch 6/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.9459\n",
      "Epoch 7/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1714 - accuracy: 0.9492\n",
      "Epoch 8/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.1637 - accuracy: 0.9515\n",
      "Epoch 9/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9538\n",
      "Epoch 10/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.1488 - accuracy: 0.9566\n",
      "Epoch 11/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1443 - accuracy: 0.9572\n",
      "Epoch 12/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1389 - accuracy: 0.9586\n",
      "Epoch 13/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1322 - accuracy: 0.9609\n",
      "Epoch 14/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1274 - accuracy: 0.9617\n",
      "Epoch 15/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1241 - accuracy: 0.9632\n",
      "Epoch 16/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1204 - accuracy: 0.9640\n",
      "Epoch 17/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1185 - accuracy: 0.9633\n",
      "Epoch 18/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1137 - accuracy: 0.9659\n",
      "Epoch 19/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.1106 - accuracy: 0.9665\n",
      "Epoch 20/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1062 - accuracy: 0.9678\n",
      "Epoch 21/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.1035 - accuracy: 0.9680\n",
      "Epoch 22/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.1028 - accuracy: 0.9685\n",
      "Epoch 23/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9695\n",
      "Epoch 24/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9695\n",
      "Epoch 25/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0948 - accuracy: 0.9708\n",
      "Epoch 26/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0922 - accuracy: 0.9718\n",
      "Epoch 27/100\n",
      "525/525 [==============================] - 3s 5ms/step - loss: 0.0915 - accuracy: 0.9716\n",
      "Epoch 28/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0881 - accuracy: 0.9720\n",
      "Epoch 29/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0864 - accuracy: 0.9729\n",
      "Epoch 30/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.9734\n",
      "Epoch 31/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0834 - accuracy: 0.9745\n",
      "Epoch 32/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0801 - accuracy: 0.9746\n",
      "Epoch 33/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0805 - accuracy: 0.9740\n",
      "Epoch 34/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0778 - accuracy: 0.9753\n",
      "Epoch 35/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.9771\n",
      "Epoch 36/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0758 - accuracy: 0.9757\n",
      "Epoch 37/100\n",
      "525/525 [==============================] - 2s 4ms/step - loss: 0.0737 - accuracy: 0.9766\n",
      "Epoch 38/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0718 - accuracy: 0.9771\n",
      "Epoch 39/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0693 - accuracy: 0.9781\n",
      "Epoch 40/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0674 - accuracy: 0.9787\n",
      "Epoch 41/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0692 - accuracy: 0.9776\n",
      "Epoch 42/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0656 - accuracy: 0.9797\n",
      "Epoch 43/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0642 - accuracy: 0.9798\n",
      "Epoch 44/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9798\n",
      "Epoch 45/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0631 - accuracy: 0.9800\n",
      "Epoch 46/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0625 - accuracy: 0.9803\n",
      "Epoch 47/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0597 - accuracy: 0.9812\n",
      "Epoch 48/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9811\n",
      "Epoch 49/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0588 - accuracy: 0.9807\n",
      "Epoch 50/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9831\n",
      "Epoch 51/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0543 - accuracy: 0.9832\n",
      "Epoch 52/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0563 - accuracy: 0.9818\n",
      "Epoch 53/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0540 - accuracy: 0.9832\n",
      "Epoch 54/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.9831\n",
      "Epoch 55/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9835\n",
      "Epoch 56/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0520 - accuracy: 0.9831\n",
      "Epoch 57/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0502 - accuracy: 0.9840\n",
      "Epoch 58/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0494 - accuracy: 0.9836\n",
      "Epoch 59/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0491 - accuracy: 0.9838\n",
      "Epoch 60/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0487 - accuracy: 0.9845\n",
      "Epoch 61/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0468 - accuracy: 0.9850\n",
      "Epoch 62/100\n",
      "525/525 [==============================] - 2s 4ms/step - loss: 0.0471 - accuracy: 0.9849\n",
      "Epoch 63/100\n",
      "525/525 [==============================] - 2s 4ms/step - loss: 0.0460 - accuracy: 0.9862\n",
      "Epoch 64/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.9857\n",
      "Epoch 65/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0446 - accuracy: 0.9857\n",
      "Epoch 66/100\n",
      "525/525 [==============================] - 3s 5ms/step - loss: 0.0428 - accuracy: 0.9867\n",
      "Epoch 67/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0436 - accuracy: 0.9858\n",
      "Epoch 68/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9870\n",
      "Epoch 69/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9859\n",
      "Epoch 70/100\n",
      "525/525 [==============================] - 3s 5ms/step - loss: 0.0416 - accuracy: 0.9864\n",
      "Epoch 71/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0419 - accuracy: 0.9866\n",
      "Epoch 72/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9858\n",
      "Epoch 73/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9877\n",
      "Epoch 74/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0371 - accuracy: 0.9876\n",
      "Epoch 75/100\n",
      "525/525 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.9885\n",
      "Epoch 76/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0368 - accuracy: 0.9882\n",
      "Epoch 77/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.9880\n",
      "Epoch 78/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9885\n",
      "Epoch 79/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9890\n",
      "Epoch 80/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0352 - accuracy: 0.9888\n",
      "Epoch 81/100\n",
      "525/525 [==============================] - 2s 3ms/step - loss: 0.0348 - accuracy: 0.9891\n",
      "Epoch 82/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0325 - accuracy: 0.9896\n",
      "Epoch 83/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9891\n",
      "Epoch 84/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0329 - accuracy: 0.9896\n",
      "Epoch 85/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0319 - accuracy: 0.9893\n",
      "Epoch 86/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0313 - accuracy: 0.9898\n",
      "Epoch 87/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9900\n",
      "Epoch 88/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9900\n",
      "Epoch 89/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0286 - accuracy: 0.9913\n",
      "Epoch 90/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9905\n",
      "Epoch 91/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9901\n",
      "Epoch 92/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.9907\n",
      "Epoch 93/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9905\n",
      "Epoch 94/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9917\n",
      "Epoch 95/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9914\n",
      "Epoch 96/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9918\n",
      "Epoch 97/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9898\n",
      "Epoch 98/100\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9906\n",
      "Epoch 99/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9911\n",
      "Epoch 100/100\n",
      "525/525 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20bc3f42150>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(784,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_pixel_data, train_label_data, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 7s 24ms/step - loss: 0.3449 - accuracy: 0.9444\n",
      "Test accuracy: 0.9444047808647156\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_pixel_data, test_label_data)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for flatten_6:\n",
      "[]\n",
      "\n",
      "\n",
      "Weights for dense_15:\n",
      "[array([[ 0.06244415, -0.08161046,  0.08079821, ..., -0.0748068 ,\n",
      "        -0.00098791, -0.08099478],\n",
      "       [-0.07810221,  0.0456368 ,  0.04988405, ..., -0.06746101,\n",
      "        -0.08090802,  0.01250552],\n",
      "       [ 0.04726851, -0.00733835,  0.06641787, ..., -0.05944957,\n",
      "        -0.08567484,  0.04144885],\n",
      "       ...,\n",
      "       [-0.07226386, -0.06131878,  0.08163793, ...,  0.0483036 ,\n",
      "        -0.07114488,  0.01632155],\n",
      "       [-0.07752825, -0.03794706,  0.08330959, ...,  0.01528356,\n",
      "         0.03667387,  0.02981323],\n",
      "       [-0.08122917,  0.00038832, -0.05326494, ...,  0.01792125,\n",
      "         0.03189135,  0.01336211]], dtype=float32), array([ 0.49257824, -0.18426004, -0.26732492,  0.15231194, -0.17170641,\n",
      "       -0.00476993,  0.20893773, -0.05723006,  0.4147451 ,  0.42521653,\n",
      "        0.3976518 ,  0.22327699,  0.64848155,  0.35524738,  0.28066972,\n",
      "        0.20014672], dtype=float32)]\n",
      "\n",
      "\n",
      "Weights for dense_16:\n",
      "[array([[ 7.6997441e-01, -1.3865143e-01,  2.7380994e-01,  1.2382688e-01,\n",
      "        -1.9060776e-01, -9.0044312e-02, -1.8207055e-01, -6.1675500e-02,\n",
      "         1.1305906e-01, -6.4261413e-01,  5.9417909e-01,  5.1329088e-01,\n",
      "        -5.9446704e-01, -2.2705950e-01,  2.4528760e-01,  9.2163920e-01],\n",
      "       [ 4.9452132e-01, -7.4667090e-01,  5.8812910e-01,  6.4214271e-01,\n",
      "         5.0762534e-01, -9.4576046e-02, -4.0113991e-01, -2.6138493e-01,\n",
      "         3.5127947e-01,  5.2760136e-01, -1.6083674e-01,  5.1161391e-01,\n",
      "        -2.1352811e-01, -3.2759243e-01, -8.9877498e-01, -5.5050021e-01],\n",
      "       [-3.5840750e-01,  2.8002524e-01,  4.0149093e-01,  3.5959336e-01,\n",
      "         4.4285893e-01, -8.7611538e-01, -3.3607077e-02,  1.2191692e-01,\n",
      "         9.9118836e-02, -8.6213696e-01, -8.9047575e-01, -4.9363899e-01,\n",
      "         8.6750209e-01, -5.0450921e-01, -1.0790621e+00,  4.2033067e-01],\n",
      "       [ 6.1840427e-01,  1.2777743e+00, -5.6187987e-01,  1.1024445e+00,\n",
      "         4.9623847e-01, -1.0743525e-01,  8.5427344e-02,  2.4446166e-01,\n",
      "        -3.6802366e-01,  7.0273060e-01, -4.8567766e-01, -1.3332137e+00,\n",
      "         1.3800757e-01, -5.7434207e-01,  2.3507603e-01, -2.3535314e-01],\n",
      "       [-5.2114081e-01, -2.7237257e-01,  1.9603178e-03, -4.0485767e-01,\n",
      "         1.2773733e+00, -6.1133122e-01,  9.3134753e-02, -4.1419381e-01,\n",
      "        -4.4619092e-01, -1.6648158e-01, -3.7048814e-01, -8.5907742e-02,\n",
      "        -3.9817911e-01,  7.4215883e-01,  3.5762104e-01,  9.9279189e-01],\n",
      "       [ 1.7586023e-01,  6.1094612e-01, -5.8119845e-01,  3.8480437e-01,\n",
      "         8.7407786e-01,  1.4897999e-01,  1.1282192e-03, -1.4031440e-01,\n",
      "         3.9639673e-01,  3.8599740e-03,  7.3479247e-01,  1.1496255e-01,\n",
      "         4.9879891e-01,  4.2264569e-01,  2.6927552e-01, -4.3121490e-01],\n",
      "       [ 4.6629325e-01, -2.8350300e-01,  9.9546951e-01, -1.1782878e-01,\n",
      "        -7.9109412e-01, -1.7589858e-02, -2.5880280e-01, -9.0246536e-02,\n",
      "         5.0652933e-01,  3.6494493e-01, -1.2010767e+00, -1.5973774e-01,\n",
      "         1.6909435e-01,  1.2239583e+00, -1.9313028e-01,  8.9613849e-01],\n",
      "       [-7.0781976e-01, -3.6674193e-01, -1.1180782e+00,  3.5008085e-01,\n",
      "         3.3504605e-01,  2.8804100e-01,  2.3585717e-01,  6.6993251e-02,\n",
      "         5.3009909e-01, -8.0592537e-01, -1.7882319e-01, -1.6909951e-02,\n",
      "         1.0779294e+00, -1.0531652e-01, -1.7110510e-01,  1.3356849e+00],\n",
      "       [ 7.5734073e-01, -3.6205950e-01, -3.4564114e-01,  1.0162117e+00,\n",
      "        -6.4928478e-01,  4.7870201e-01,  2.5180849e-01, -1.8611607e-01,\n",
      "        -1.8074171e-01, -1.1296308e+00,  1.2676201e+00, -1.0719051e+00,\n",
      "         6.7054576e-01,  7.4929988e-01, -7.9059720e-02,  1.7046480e-01],\n",
      "       [ 3.0198699e-01,  9.4718599e-01,  5.6588954e-01, -3.2829443e-01,\n",
      "         3.3374265e-01,  2.0253547e-01, -4.4616497e-01, -1.2325576e-01,\n",
      "        -4.2830014e-01, -4.7483656e-01,  7.4527478e-01, -1.1955795e-01,\n",
      "         6.3640249e-01, -4.3621555e-01, -6.4366244e-02, -2.6014751e-01],\n",
      "       [-4.8123911e-01, -4.8906800e-01, -1.1551310e+00,  7.7520001e-01,\n",
      "        -4.5917328e-02,  1.0158569e+00,  8.8966809e-02, -2.3563901e-01,\n",
      "         1.0609598e+00,  3.4560007e-01,  2.7286541e-01, -2.2541896e-01,\n",
      "        -3.5665151e-01,  6.4762461e-01, -2.3797272e-01, -5.8928061e-01],\n",
      "       [-3.6564663e-01, -1.6371512e-01, -6.0445255e-01,  8.7611753e-01,\n",
      "        -5.4833323e-01,  2.3895469e-01, -3.2298520e-02,  3.1707060e-01,\n",
      "         1.1481622e+00,  5.7977462e-01,  3.1674728e-01,  3.8587776e-01,\n",
      "        -1.5398346e-01, -1.7114559e-01,  4.3409908e-01,  1.5323679e-01],\n",
      "       [-7.9546601e-01,  5.7468194e-01,  2.4772781e-01,  3.4764329e-01,\n",
      "        -4.0248880e-01,  8.0127424e-01, -9.7645834e-02, -1.2414362e-01,\n",
      "         6.6832952e-02,  1.5035987e-01,  3.4024817e-01,  7.0613283e-01,\n",
      "        -3.3643371e-01,  5.1920009e-01, -1.6965258e-01, -8.4742445e-01],\n",
      "       [ 3.7349716e-01,  1.2389061e+00,  8.2856417e-02, -6.8904048e-01,\n",
      "         2.3037519e-01,  2.6279396e-01, -4.2423511e-01, -2.7274793e-01,\n",
      "        -1.0164157e+00,  1.2995315e+00, -3.8451424e-01,  5.3583807e-01,\n",
      "        -7.1303916e-01, -1.4514023e-01, -1.4358144e-01, -1.6514201e-01],\n",
      "       [-7.0341319e-01,  3.2571945e-01, -1.1494231e-01,  1.8059762e-01,\n",
      "        -2.5357568e-01, -9.9389845e-01, -3.9193797e-01, -3.4430730e-01,\n",
      "        -2.8358102e-01,  5.9950733e-01, -9.3354836e-02,  5.9818214e-01,\n",
      "         2.3511058e-01, -8.6769462e-01, -8.6771287e-02,  5.8809727e-01],\n",
      "       [-1.7729567e-01,  7.9439126e-02,  7.6443911e-01, -8.7739998e-01,\n",
      "         4.8846629e-01, -4.2642125e-01, -2.9337105e-01,  1.6711906e-02,\n",
      "        -3.1293649e-02,  7.4143606e-01,  6.6856003e-01, -4.9831334e-01,\n",
      "         2.4396250e-01,  1.6652317e-01,  2.7368736e-01, -2.7355033e-01]],\n",
      "      dtype=float32), array([-0.44582617, -0.00424092,  0.436535  , -0.44440165, -0.27803037,\n",
      "        0.7680093 , -0.11380098,  0.02157769,  0.3224795 ,  0.3171019 ,\n",
      "       -0.05342717,  0.22889948,  0.24743204,  0.19950376,  0.39506495,\n",
      "        0.47576493], dtype=float32)]\n",
      "\n",
      "\n",
      "Weights for dense_17:\n",
      "[array([[ 0.28124616,  1.2318823 ,  0.6614214 ,  0.3745282 ,  0.80666584,\n",
      "        -1.6291668 , -1.7790397 ,  0.11504118, -0.7467943 ,  0.56297845],\n",
      "       [-1.3223633 , -0.2055684 , -0.1747518 , -0.50444955,  0.540943  ,\n",
      "        -1.4156634 ,  0.08759253,  0.67564905, -0.4207611 ,  0.2746106 ],\n",
      "       [-0.5368085 , -0.92454123,  1.0564783 ,  0.11921334,  0.5341768 ,\n",
      "        -0.8181356 , -0.05006566, -0.15565775,  0.07634345, -1.272113  ],\n",
      "       [ 0.26478627, -1.6216162 , -0.7100882 , -0.01122329,  0.10076465,\n",
      "         0.6377084 ,  0.41842026, -0.65855706, -0.53803384,  0.57542264],\n",
      "       [ 0.5623142 , -0.49479815,  0.17158379,  0.22890696, -0.9364495 ,\n",
      "         0.01134026, -1.124541  ,  0.9511619 , -0.169857  , -0.00898727],\n",
      "       [-0.47042406,  1.0279775 , -0.16634496, -0.787947  ,  1.0220032 ,\n",
      "         0.5424141 , -1.9640418 ,  0.56556684, -1.0053207 , -1.0438541 ],\n",
      "       [-0.38311312,  0.22186166, -0.3992109 , -0.4682982 , -0.09076777,\n",
      "        -0.1627422 ,  0.20821199, -0.39243343,  0.44428706,  0.13502516],\n",
      "       [-0.04350359,  0.2455498 ,  0.17113276, -0.11308832,  0.4315113 ,\n",
      "         0.14780973,  0.39516154,  0.44911394, -0.49400938,  0.40426496],\n",
      "       [ 0.50936234,  0.19661091, -1.2052236 ,  0.59256876, -0.1793221 ,\n",
      "         0.6812238 ,  0.477192  , -1.0465618 , -0.05814799, -0.39419582],\n",
      "       [ 0.96704894,  0.90410423, -0.8788976 , -1.266132  ,  0.5011513 ,\n",
      "        -1.1164458 ,  0.86029935,  0.3432642 , -0.27300924,  0.15250513],\n",
      "       [-1.1826913 ,  0.31541726, -0.3955398 ,  0.17600724, -0.28249598,\n",
      "         0.29485738, -1.0147083 , -0.20288336,  1.0259016 ,  0.4783364 ],\n",
      "       [ 0.2390668 , -0.73054147,  0.05367667, -0.693582  , -0.54833615,\n",
      "        -0.29094678,  0.86774945, -0.7854782 ,  0.5131967 , -0.11536577],\n",
      "       [-1.1997313 ,  0.36597794,  0.05662577,  1.3597163 , -0.49389887,\n",
      "        -0.43762714, -1.4098605 , -0.48979127, -0.3122963 ,  0.12436406],\n",
      "       [ 0.6691643 , -1.180476  ,  1.0101326 , -0.9657416 , -0.60175383,\n",
      "         1.312176  , -1.3220193 ,  1.258492  ,  0.20525624, -0.28577057],\n",
      "       [-1.4401083 ,  0.36540526,  0.83641464, -1.3163495 ,  0.7826182 ,\n",
      "        -0.03266016, -2.2861316 , -0.64772856, -1.105308  ,  0.8532959 ],\n",
      "       [-1.180308  ,  1.2290578 ,  0.43091112, -0.85189605, -0.89183295,\n",
      "         0.29783148,  0.22527389, -0.08720467, -1.2196931 , -1.5281216 ]],\n",
      "      dtype=float32), array([-0.2294742 ,  0.62779737,  0.68060356, -0.30584013,  0.03760014,\n",
      "        0.14538155,  0.11942914, -0.22818176, -0.14179082, -0.38017976],\n",
      "      dtype=float32)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    As of now, I do not know what useful information this provides, but I just thought it would be cool to be able to see\n",
    "    the weights in the layers of the NN. It is interesting how these weights map to features representative of \n",
    "    the world.\n",
    "\"\"\"\n",
    "for layer in model.layers:\n",
    "    print(f\"Weights for {layer.name}:\")\n",
    "    print(layer.get_weights())\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
